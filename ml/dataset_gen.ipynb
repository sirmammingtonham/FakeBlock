{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the data in a format our training script can use\n",
    "# https://www.uvic.ca/engineering/ece/isot/datasets/fake-news/index.php\n",
    "with open('../../News _dataset/Fake.csv', 'r', encoding='utf-8') as fake:\n",
    "    with open('../../News _dataset/True.csv', 'r', encoding='utf-8') as real:\n",
    "        with open('./datasets/ISOT_FakeNews.csv', 'w+', newline='', encoding='utf-8') as out:\n",
    "            fakeReader = csv.reader(fake, delimiter=',')\n",
    "            realReader = csv.reader(real, delimiter=',')\n",
    "            next(fakeReader)\n",
    "            next(realReader)\n",
    "            output = csv.writer(out, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "            output.writerow(['label', 'headline', 'text'])\n",
    "            for line in fakeReader:\n",
    "                output.writerow(['1', line[0], line[1]])\n",
    "            for line in realReader:\n",
    "                output.writerow(['0', line[0], line[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/ISOT_FakeNews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data and generate our train valid test split\n",
    "train, valid, test = np.split(df.sample(frac=1, random_state=42), [int(.6*len(df)), int(.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('datasets/ISOT_train.csv', index=False)\n",
    "valid.to_csv('datasets/ISOT_valid.csv', index=False)\n",
    "test.to_csv('datasets/ISOT_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default-9b9f86091f19c68a\n",
      "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to C:\\Users\\ethan\\.cache\\huggingface\\datasets\\csv\\default-9b9f86091f19c68a\\0.0.0\\2a88c45fed596f9421a2e7f74ab1a3cd012ef75210a5dc1950e8d60ca8d9c66c...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24b62434e6f44c159fc90f0a33ee94db"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ""
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96fa1cecce2a401fa6c0c49b2712e0ee"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ""
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0725f29ee6a34219aa266b0192d070c7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\ethan\\.cache\\huggingface\\datasets\\csv\\default-9b9f86091f19c68a\\0.0.0\\2a88c45fed596f9421a2e7f74ab1a3cd012ef75210a5dc1950e8d60ca8d9c66c. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "train_file = './datasets/ISOT_train.csv'\n",
    "eval_file = './datasets/ISOT_valid.csv'\n",
    "test_file = './datasets/ISOT_test.csv'\n",
    "files = {}\n",
    "if train_file is not None:\n",
    "    files[datasets.Split.TRAIN] = [train_file]\n",
    "if eval_file is not None:\n",
    "    files[datasets.Split.VALIDATION] = [eval_file]\n",
    "if test_file is not None:\n",
    "    files[datasets.Split.TEST] = [test_file]\n",
    "\n",
    "ds = datasets.load_dataset(\"csv\", data_files=files, quotechar='\"')\n",
    "features_name = list(ds[list(files.keys())[0]].features.keys())\n",
    "label_name = features_name.pop(0)\n",
    "label_list = list(set(ds[list(files.keys())[0]][label_name]))\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "# input_names = tokenizer.model_input_names\n",
    "transformed_ds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f72a975bfb3457b9ac9171e98873ee4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'headline', 'text'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# test_ds = ds['test'].select(range(10))\n",
    "for x in test_ds:\n",
    "    print(type(x[features_name[1]]))\n",
    "\n",
    "test_ds.map(lambda x: print(type(x[features_name[1]])), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plswork(example):\n",
    "    # print(type(example[features_name[1]]))\n",
    "    try:\n",
    "        ret = tokenizer.batch_encode_plus(\n",
    "            (example[features_name[0]], example[features_name[1]]),\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        # print(example[features_name[0]])\n",
    "        print(len(example[features_name[0]]))\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "batch_text_or_text_pairs has to be a list (got <class 'tuple'>)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-7542e4446fa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m transformed_ds['test'] = ds['test'].select(range(10)).map(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mplswork\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mbatched\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32mF:\\conda\\envs\\fakeblock\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, function, with_indices, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint)\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[0mtest_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbatched\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[0mtest_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbatched\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1289\u001b[1;33m         \u001b[0mupdate_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoes_function_return_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1290\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing finished, running the mapping function on the dataset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\conda\\envs\\fakeblock\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36mdoes_function_return_dict\u001b[1;34m(inputs, indices)\u001b[0m\n\u001b[0;32m   1258\u001b[0m             \u001b[0mfn_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minput_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m             processed_inputs = (\n\u001b[1;32m-> 1260\u001b[1;33m                 \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mwith_indices\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1261\u001b[0m             )\n\u001b[0;32m   1262\u001b[0m             \u001b[0mdoes_return_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-ebffe988aca3>\u001b[0m in \u001b[0;36mplswork\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# print(example[features_name[0]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-ebffe988aca3>\u001b[0m in \u001b[0;36mplswork\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# print(type(example[features_name[1]]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         ret = tokenizer.batch_encode_plus(\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\conda\\envs\\fakeblock\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2513\u001b[0m         )\n\u001b[0;32m   2514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2515\u001b[1;33m         return self._batch_encode_plus(\n\u001b[0m\u001b[0;32m   2516\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2517\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\conda\\envs\\fakeblock\\lib\\site-packages\\transformers\\tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    370\u001b[0m                 \u001b[1;34m\"batch_text_or_text_pairs has to be a list (got {})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             )\n",
      "\u001b[1;31mTypeError\u001b[0m: batch_text_or_text_pairs has to be a list (got <class 'tuple'>)"
     ]
    }
   ],
   "source": [
    "transformed_ds['test'] = ds['test'].select(range(10)).map(\n",
    "    plswork,\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2197, 2095, 1037, 8075, 22613, 2001, 3236, 19535, 21887, 23350, 2013, 2710, 1012, 2009, 2001, 9551, 2000, 2822, 6074, 2551, 2012, 1037, 3010, 6845, 1012, 4745, 4812, 2011, 2307, 16650, 22254, 2401, 5799, 1996, 6074, 2000, 2822, 6897, 8309, 2565, 2013, 2073, 1996, 7865, 2003, 6878, 2000, 2031, 15748, 4786, 1996, 8814, 4819, 21887, 23350, 8293, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "tokenizer(['Last year a mysterious shipment was caught smuggling Coronavirus from Canada. It was traced to Chinese agents working at a Canadian lab. Subsequent investigation by GreatGameIndia linked the agents to Chinese Biological Warfare Program from where the virus is suspected to have leaked causing the Wuhan Coronavirus outbreak.'], truncation=True, max_length=512, padding='max_length')"
   ]
  },
  {
   "source": [
    "# New dataset! NELA-GT-2019"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            source  aggregated_label  Pew Research Center, known_by_40%  \\\n",
       "0  21stcenturywire               2.0                                NaN   \n",
       "1          abcnews               0.0                                1.0   \n",
       "2     activistpost               2.0                                NaN   \n",
       "3    addictinginfo               1.0                                NaN   \n",
       "4  adobochronicles               NaN                                NaN   \n",
       "\n",
       "   Pew Research Center, total  Pew Research Center, consistently_liberal  \\\n",
       "0                         NaN                                        NaN   \n",
       "1                         1.0                                        1.0   \n",
       "2                         NaN                                        NaN   \n",
       "3                         NaN                                        NaN   \n",
       "4                         NaN                                        NaN   \n",
       "\n",
       "   Pew Research Center, mostly_liberal  Pew Research Center, mixed  \\\n",
       "0                                  NaN                         NaN   \n",
       "1                                  1.0                         1.0   \n",
       "2                                  NaN                         NaN   \n",
       "3                                  NaN                         NaN   \n",
       "4                                  NaN                         NaN   \n",
       "\n",
       "   Pew Research Center, mostly conservative  \\\n",
       "0                                       NaN   \n",
       "1                                       1.0   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "   Pew Research Center, consistently conservative  Wikipedia, is_fake  ...  \\\n",
       "0                                             NaN                 NaN  ...   \n",
       "1                                            -1.0                 NaN  ...   \n",
       "2                                             NaN                 NaN  ...   \n",
       "3                                             NaN                 NaN  ...   \n",
       "4                                             NaN                 NaN  ...   \n",
       "\n",
       "   Allsides, community_agree  Allsides, community_disagree  \\\n",
       "0                        NaN                           NaN   \n",
       "1                     8964.0                        6949.0   \n",
       "2                        NaN                           NaN   \n",
       "3                        NaN                           NaN   \n",
       "4                        NaN                           NaN   \n",
       "\n",
       "   Allsides, community_label  BuzzFeed, leaning  PolitiFact, Pants on Fire!  \\\n",
       "0                        NaN               left                         NaN   \n",
       "1             somewhat agree                NaN                         NaN   \n",
       "2                        NaN               left                         NaN   \n",
       "3                        NaN               left                         NaN   \n",
       "4                        NaN                NaN                         NaN   \n",
       "\n",
       "   PolitiFact, False  PolitiFact, Mostly False  PolitiFact, Half-True  \\\n",
       "0                NaN                       NaN                    NaN   \n",
       "1                NaN                       NaN                    NaN   \n",
       "2                NaN                       NaN                    NaN   \n",
       "3                NaN                       NaN                    NaN   \n",
       "4                NaN                       NaN                    NaN   \n",
       "\n",
       "   PolitiFact, Mostly True  PolitiFact, True  \n",
       "0                      NaN               NaN  \n",
       "1                      NaN               NaN  \n",
       "2                      NaN               NaN  \n",
       "3                      NaN               NaN  \n",
       "4                      NaN               NaN  \n",
       "\n",
       "[5 rows x 48 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>aggregated_label</th>\n      <th>Pew Research Center, known_by_40%</th>\n      <th>Pew Research Center, total</th>\n      <th>Pew Research Center, consistently_liberal</th>\n      <th>Pew Research Center, mostly_liberal</th>\n      <th>Pew Research Center, mixed</th>\n      <th>Pew Research Center, mostly conservative</th>\n      <th>Pew Research Center, consistently conservative</th>\n      <th>Wikipedia, is_fake</th>\n      <th>...</th>\n      <th>Allsides, community_agree</th>\n      <th>Allsides, community_disagree</th>\n      <th>Allsides, community_label</th>\n      <th>BuzzFeed, leaning</th>\n      <th>PolitiFact, Pants on Fire!</th>\n      <th>PolitiFact, False</th>\n      <th>PolitiFact, Mostly False</th>\n      <th>PolitiFact, Half-True</th>\n      <th>PolitiFact, Mostly True</th>\n      <th>PolitiFact, True</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>21stcenturywire</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>left</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abcnews</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>8964.0</td>\n      <td>6949.0</td>\n      <td>somewhat agree</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>activistpost</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>left</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>addictinginfo</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>left</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>adobochronicles</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 48 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "label_df = pd.read_csv('./datasets/NELA/labels.csv')\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_df[label_df['aggregated_label'].notnull() or label_df['Media Bias / Fact Check, label'].notnull()]\n",
    "label_df = label_df.dropna(subset=['aggregated_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['Media Bias / Fact Check, label'] = label_df['Media Bias / Fact Check, label'].astype('category')\n",
    "label_df['Media Bias / Fact Check, label'] = label_df['Media Bias / Fact Check, label'].cat.add_categories(\"NA\").fillna(\"NA\")\n",
    "cat_map = dict( enumerate(label_df['Media Bias / Fact Check, label'].cat.categories ) )\n",
    "label_df['Media Bias / Fact Check, label'] = label_df['Media Bias / Fact Check, label'].cat.codes\n",
    "# label_df['Media Bias / Fact Check, label'] = label_df['Media Bias / Fact Check, label'].fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_str = [\"'%s'\" % s for s in label_df['source']]\n",
    "query = \"SELECT * FROM newsdata WHERE source IN (%s)\" % \",\".join(sources_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  id        date  \\\n",
       "0  thenewyorktimes--2019-01-30--Fed Signals End o...  2019-01-30   \n",
       "1  thenewyorktimes--2019-01-30--Judiciary Hearing...  2019-01-30   \n",
       "2  thenewyorktimes--2019-01-30--Chris Christie Sa...  2019-01-30   \n",
       "3  thenewyorktimes--2019-01-30--White House Memo ...  2019-01-30   \n",
       "4  thenewyorktimes--2019-01-30--Fed Expected to H...  2019-01-30   \n",
       "\n",
       "            source                                              title  \\\n",
       "0  thenewyorktimes         Fed Signals End of Interest Rate Increases   \n",
       "1  thenewyorktimes  Judiciary Hearing on Democrats’ Election Bill ...   \n",
       "2  thenewyorktimes  Chris Christie Says Jared Kushner’s Father Com...   \n",
       "3  thenewyorktimes  White House Memo: The Many Ways to Leave the W...   \n",
       "4  thenewyorktimes  Fed Expected to Hold Rates Steady and Emphasiz...   \n",
       "\n",
       "                                             content  \\\n",
       "0  WASHINGTON — The Federal Reserve stepped hard ...   \n",
       "1  “ This sprawling , comprehensive proposal is b...   \n",
       "2  Chris Christie , the former New Jersey governo...   \n",
       "3  WASHINGTON — In an interview on Monday on “ Go...   \n",
       "4  WASHINGTON — The Federal Reserve has adopted a...   \n",
       "\n",
       "                            author  \\\n",
       "0               BINYAMIN APPELBAUM   \n",
       "1                   EMILY COCHRANE   \n",
       "2                    DANIEL VICTOR   \n",
       "3  ANNIE KARNI and MAGGIE HABERMAN   \n",
       "4               BINYAMIN APPELBAUM   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.nytimes.com/2019/01/30/us/politics...   \n",
       "1  https://www.nytimes.com/2019/01/29/us/politics...   \n",
       "2  https://www.nytimes.com/2019/01/30/us/politics...   \n",
       "3  https://www.nytimes.com/2019/01/29/us/politics...   \n",
       "4  https://www.nytimes.com/2019/01/30/us/politics...   \n",
       "\n",
       "                   published  published_utc  collection_utc  \n",
       "0  2019-01-30 19:14:28+00:00     1548893668      1567550256  \n",
       "1  2019-01-30 00:34:08+00:00     1548826448      1567550256  \n",
       "2  2019-01-30 16:31:52+00:00     1548883912      1567550256  \n",
       "3  2019-01-30 03:44:00+00:00     1548837840      1567550256  \n",
       "4  2019-01-30 10:00:13+00:00     1548860413      1567550256  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>date</th>\n      <th>source</th>\n      <th>title</th>\n      <th>content</th>\n      <th>author</th>\n      <th>url</th>\n      <th>published</th>\n      <th>published_utc</th>\n      <th>collection_utc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>thenewyorktimes--2019-01-30--Fed Signals End o...</td>\n      <td>2019-01-30</td>\n      <td>thenewyorktimes</td>\n      <td>Fed Signals End of Interest Rate Increases</td>\n      <td>WASHINGTON — The Federal Reserve stepped hard ...</td>\n      <td>BINYAMIN APPELBAUM</td>\n      <td>https://www.nytimes.com/2019/01/30/us/politics...</td>\n      <td>2019-01-30 19:14:28+00:00</td>\n      <td>1548893668</td>\n      <td>1567550256</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>thenewyorktimes--2019-01-30--Judiciary Hearing...</td>\n      <td>2019-01-30</td>\n      <td>thenewyorktimes</td>\n      <td>Judiciary Hearing on Democrats’ Election Bill ...</td>\n      <td>“ This sprawling , comprehensive proposal is b...</td>\n      <td>EMILY COCHRANE</td>\n      <td>https://www.nytimes.com/2019/01/29/us/politics...</td>\n      <td>2019-01-30 00:34:08+00:00</td>\n      <td>1548826448</td>\n      <td>1567550256</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thenewyorktimes--2019-01-30--Chris Christie Sa...</td>\n      <td>2019-01-30</td>\n      <td>thenewyorktimes</td>\n      <td>Chris Christie Says Jared Kushner’s Father Com...</td>\n      <td>Chris Christie , the former New Jersey governo...</td>\n      <td>DANIEL VICTOR</td>\n      <td>https://www.nytimes.com/2019/01/30/us/politics...</td>\n      <td>2019-01-30 16:31:52+00:00</td>\n      <td>1548883912</td>\n      <td>1567550256</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>thenewyorktimes--2019-01-30--White House Memo ...</td>\n      <td>2019-01-30</td>\n      <td>thenewyorktimes</td>\n      <td>White House Memo: The Many Ways to Leave the W...</td>\n      <td>WASHINGTON — In an interview on Monday on “ Go...</td>\n      <td>ANNIE KARNI and MAGGIE HABERMAN</td>\n      <td>https://www.nytimes.com/2019/01/29/us/politics...</td>\n      <td>2019-01-30 03:44:00+00:00</td>\n      <td>1548837840</td>\n      <td>1567550256</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>thenewyorktimes--2019-01-30--Fed Expected to H...</td>\n      <td>2019-01-30</td>\n      <td>thenewyorktimes</td>\n      <td>Fed Expected to Hold Rates Steady and Emphasiz...</td>\n      <td>WASHINGTON — The Federal Reserve has adopted a...</td>\n      <td>BINYAMIN APPELBAUM</td>\n      <td>https://www.nytimes.com/2019/01/30/us/politics...</td>\n      <td>2019-01-30 10:00:13+00:00</td>\n      <td>1548860413</td>\n      <td>1567550256</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "conn = sqlite3.connect(r'D:\\datasets\\dataverse_files_2019\\nela-gt-2019.db')\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(label_df, on='source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'date': Value(dtype='string', id=None),\n",
       " 'source': Value(dtype='string', id=None),\n",
       " 'title': Value(dtype='string', id=None),\n",
       " 'content': Value(dtype='string', id=None),\n",
       " 'author': Value(dtype='string', id=None),\n",
       " 'url': Value(dtype='string', id=None),\n",
       " 'published': Value(dtype='string', id=None),\n",
       " 'published_utc': Value(dtype='int64', id=None),\n",
       " 'collection_utc': Value(dtype='int64', id=None),\n",
       " 'aggregated_label': ClassLabel(num_classes=3, names=['reliable', 'mixed', 'unreliable'], names_file=None, id=None),\n",
       " 'Pew Research Center, known_by_40%': Value(dtype='int64', id=None),\n",
       " 'Pew Research Center, total': Value(dtype='int64', id=None),\n",
       " 'Pew Research Center, consistently_liberal': Value(dtype='int64', id=None),\n",
       " 'Pew Research Center, mostly_liberal': Value(dtype='int64', id=None),\n",
       " 'Pew Research Center, mixed': Value(dtype='int64', id=None),\n",
       " 'Pew Research Center, mostly conservative': Value(dtype='int64', id=None),\n",
       " 'Pew Research Center, consistently conservative': Value(dtype='int64', id=None),\n",
       " 'Wikipedia, is_fake': Value(dtype='int64', id=None),\n",
       " 'Open Sources, reliable': Value(dtype='int64', id=None),\n",
       " 'Open Sources, fake': Value(dtype='int64', id=None),\n",
       " 'Open Sources, unreliable': Value(dtype='int64', id=None),\n",
       " 'Open Sources, bias': Value(dtype='int64', id=None),\n",
       " 'Open Sources, conspiracy': Value(dtype='int64', id=None),\n",
       " 'Open Sources, hate': Value(dtype='int64', id=None),\n",
       " 'Open Sources, junksci': Value(dtype='int64', id=None),\n",
       " 'Open Sources, rumor': Value(dtype='int64', id=None),\n",
       " 'Open Sources, blog': Value(dtype='int64', id=None),\n",
       " 'Open Sources, clickbait': Value(dtype='int64', id=None),\n",
       " 'Open Sources, political': Value(dtype='int64', id=None),\n",
       " 'Open Sources, satire': Value(dtype='int64', id=None),\n",
       " 'Open Sources, state': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, label': ClassLabel(num_classes=8, names=['conspiracy_pseudoscience', 'least_biased', 'left_bias', 'left_center_bias', 'questionable_source', 'right_bias', 'right_center_bias', 'NA'], names_file=None, id=None),\n",
       " 'Media Bias / Fact Check, factual_reporting': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, extreme_left': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, right': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, extreme_right': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, propaganda': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, fake_news': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, some_fake_news': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, failed_fact_checks': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, conspiracy': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, pseudoscience': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, hate_group': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, anti_islam': Value(dtype='int64', id=None),\n",
       " 'Media Bias / Fact Check, nationalism': Value(dtype='int64', id=None),\n",
       " 'Allsides, bias_rating': Value(dtype='string', id=None),\n",
       " 'Allsides, community_agree': Value(dtype='int64', id=None),\n",
       " 'Allsides, community_disagree': Value(dtype='int64', id=None),\n",
       " 'Allsides, community_label': Value(dtype='string', id=None),\n",
       " 'BuzzFeed, leaning': Value(dtype='string', id=None),\n",
       " 'PolitiFact, Pants on Fire!': Value(dtype='int64', id=None),\n",
       " 'PolitiFact, False': Value(dtype='int64', id=None),\n",
       " 'PolitiFact, Mostly False': Value(dtype='int64', id=None),\n",
       " 'PolitiFact, Half-True': Value(dtype='int64', id=None),\n",
       " 'PolitiFact, Mostly True': Value(dtype='int64', id=None),\n",
       " 'PolitiFact, True': Value(dtype='int64', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "new_features = dataset.features.copy()\n",
    "new_features['aggregated_label'] = datasets.ClassLabel(names=['reliable', 'mixed', 'unreliable'])\n",
    "new_features['Media Bias / Fact Check, label'] = datasets.ClassLabel(names=list(cat_map.values()))\n",
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9001a8f65980>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_testvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_testvalid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m split = datasets.DatasetDict({\n\u001b[0;32m      4\u001b[0m     \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_testvalid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtest_valid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_testvalid = dataset.train_test_split(test_size=0.2)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "split = datasets.DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "split.save_to_disk('./datasets/NELA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}